"""
ML Analytics API - Main Integration Module (FULLY CORRECTED)
FastAPI integration for educational ML analytics
Place in: ml-analytics/analytics/ml_analytics_api.py

FIXES:
- Grading endpoint (strategy parameter) âœ…
- Personalization endpoint (method signature) âœ…
- All method calls match actual implementations âœ…
"""

import sys
import os

# Fix imports for ml-analytics structure
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, List, Optional
import pandas as pd
import numpy as np
from datetime import datetime

# Import ML Analytics modules from correct structure
try:
    from personalization.adaptive_personalizer import AdaptivePersonalizer
    from grading.rubric_manager import RubricManager
    from grading.partial_credit import PartialCreditEngine
    from grading.feedback_generator import FeedbackGenerator
    from explainability.shap_analyzer import SHAPAnalyzer
    from explainability.feature_importance import FeatureImportance
    from utils.metrics_calculator import MetricsCalculator
    from utils.visualizations import VisualizationHelpers
except ImportError as e:
    print(f"Warning: Some modules not available: {e}")


# Initialize FastAPI app
app = FastAPI(
    title="ML Analytics API",
    description="Educational ML Analytics - Personalization, Grading, and Explainability",
    version="1.0.2"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize components
personalizer = AdaptivePersonalizer()
rubric_manager = RubricManager()
feedback_generator = FeedbackGenerator()
shap_analyzer = SHAPAnalyzer()
feature_importance = FeatureImportance()
metrics_calculator = MetricsCalculator()
viz_helpers = VisualizationHelpers()


# ============================================================================
# PYDANTIC MODELS (Request/Response Schemas)
# ============================================================================

class StudentData(BaseModel):
    """Student data matching AdaptivePersonalizer expectations"""
    student_id: str
    recent_scores: Optional[List[float]] = []
    weak_topics: Optional[List[str]] = []
    strong_topics: Optional[List[str]] = []
    current_difficulty: Optional[str] = 'Medium'
    performance_trend: Optional[str] = 'stable'

class Question(BaseModel):
    """Question structure"""
    id: str
    topic: str
    difficulty: str
    question_type: str
    bloom_level: str
    content: Optional[str] = ""

class PersonalizationRequest(BaseModel):
    """Request for personalized assignment - CORRECTED"""
    student_data: StudentData
    question_pool: List[Question]

class GradingRequest(BaseModel):
    student_answer: float
    correct_answer: float
    max_points: float
    strategy: Optional[str] = 'standard'

class FeedbackRequest(BaseModel):
    student_performance: Dict
    question_info: Optional[Dict] = None

class MetricsRequest(BaseModel):
    responses: List[Dict]
    performance_history: Optional[List[Dict]] = []


# ============================================================================
# HEALTH CHECK
# ============================================================================

@app.get("/")
def root():
    """API root endpoint"""
    return {
        "message": "ML Analytics API",
        "version": "1.0.2",
        "status": "operational",
        "fixes": [
            "Grading endpoint - strategy parameter fixed",
            "Personalization endpoint - method signature fixed",
            "All endpoints validated"
        ],
        "endpoints": {
            "personalization": "/api/personalize",
            "grading": "/api/grade",
            "feedback": "/api/feedback",
            "metrics": "/api/metrics",
            "visualization": "/api/viz/*",
            "explainability": "/api/explain",
            "health": "/health",
            "docs": "/docs"
        }
    }

@app.get("/health")
def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "personalizer": "ready",
            "grading": "ready",
            "explainability": "ready",
            "metrics": "ready",
            "visualization": "ready"
        }
    }


# ============================================================================
# PERSONALIZATION ENDPOINTS (CORRECTED)
# ============================================================================

@app.post("/api/personalize")
def personalize_assignment(request: PersonalizationRequest):
    """
    Generate personalized assignment for student

    CORRECTED: Uses student_data and question_pool parameters
    matching AdaptivePersonalizer.personalize_assignment() signature
    """
    try:
        # Convert Pydantic models to dicts
        student_data_dict = request.student_data.dict()
        question_pool_list = [q.dict() for q in request.question_pool]

        # Call with correct parameters
        assignment = personalizer.personalize_assignment(
            student_data=student_data_dict,
            question_pool=question_pool_list
        )

        return {
            "success": True,
            "assignment": assignment,
            "student_id": request.student_data.student_id
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/next-question")
def get_next_question(student_data: StudentData, 
                     recent_performance: List[Dict],
                     available_questions: List[Question]):
    """
    Get next adaptive question for student

    CORRECTED: Uses proper parameter names
    """
    try:
        # Convert to dicts
        student_data_dict = student_data.dict()
        questions_list = [q.dict() for q in available_questions]

        next_q = personalizer.get_next_question(
            student_data=student_data_dict,
            recent_performance=recent_performance,
            available_questions=questions_list
        )

        return {
            "success": True,
            "next_question": next_q,
            "student_id": student_data.student_id
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# GRADING ENDPOINTS (FIXED)
# ============================================================================

@app.post("/api/grade")
def grade_answer(request: GradingRequest):
    """
    Calculate partial credit for student answer

    FIXED: Create PartialCreditEngine instance with strategy parameter
    """
    try:
        # Create engine instance with the requested strategy
        partial_credit_engine = PartialCreditEngine(strategy=request.strategy)

        # Calculate partial credit (without strategy parameter)
        result = partial_credit_engine.calculate_partial_credit(
            student_answer=request.student_answer,
            correct_answer=request.correct_answer,
            max_points=request.max_points
        )

        return {
            "success": True,
            "grading_result": result,
            "strategy_used": request.strategy
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/create-rubric")
def create_rubric(name: str, criteria: List[Dict]):
    """Create grading rubric"""
    try:
        rubric = rubric_manager.create_rubric(name, criteria)

        return {
            "success": True,
            "rubric": rubric
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/apply-rubric")
def apply_rubric(rubric: Dict, 
                student_response: str,
                criterion_scores: Optional[Dict] = None):
    """Apply rubric to student response"""
    try:
        result = rubric_manager.apply_rubric(
            rubric=rubric,
            student_response=student_response,
            criterion_scores=criterion_scores
        )

        return {
            "success": True,
            "rubric_result": result
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/feedback")
def generate_feedback(request: FeedbackRequest):
    """Generate personalized feedback for student"""
    try:
        feedback = feedback_generator.generate_feedback(
            student_performance=request.student_performance,
            question_info=request.question_info
        )

        return {
            "success": True,
            "feedback": feedback
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# METRICS ENDPOINTS
# ============================================================================

@app.post("/api/metrics")
def calculate_metrics(request: MetricsRequest):
    """Calculate comprehensive performance metrics"""
    try:
        if request.performance_history:
            perf_df = pd.DataFrame(request.performance_history)
        else:
            perf_df = pd.DataFrame()

        student_data = {
            'responses': request.responses,
            'performance_history': perf_df
        }

        metrics = metrics_calculator.calculate_comprehensive_metrics(student_data)

        return {
            "success": True,
            "metrics": metrics
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/topic-metrics")
def get_topic_metrics(responses: List[Dict]):
    """Calculate metrics by topic"""
    try:
        topic_metrics = metrics_calculator.calculate_topic_metrics(responses)

        return {
            "success": True,
            "topic_metrics": topic_metrics
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/metrics/accuracy")
def calculate_accuracy(responses: List[Dict]):
    """Calculate overall accuracy"""
    try:
        accuracy = metrics_calculator.calculate_accuracy(responses)

        return {
            "success": True,
            "accuracy": accuracy,
            "percentage": f"{accuracy * 100:.1f}%"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# VISUALIZATION ENDPOINTS
# ============================================================================

@app.post("/api/viz/line-chart")
def get_line_chart_data(performance_history: List[Dict]):
    """Prepare line chart data for performance over time"""
    try:
        df = pd.DataFrame(performance_history)
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])

        chart_data = viz_helpers.prepare_line_chart(df)

        return {
            "success": True,
            "chart_data": chart_data,
            "chart_type": "line"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/viz/bar-chart")
def get_bar_chart_data(topic_metrics: Dict):
    """Prepare bar chart data for topic comparison"""
    try:
        chart_data = viz_helpers.prepare_bar_chart(topic_metrics)

        return {
            "success": True,
            "chart_data": chart_data,
            "chart_type": "bar"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/viz/dashboard")
def get_dashboard_data(metrics: Dict):
    """Prepare dashboard summary cards"""
    try:
        dashboard = viz_helpers.prepare_dashboard_summary(metrics)

        return {
            "success": True,
            "dashboard": dashboard
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/viz/leaderboard")
def get_leaderboard(students: List[Dict], 
                   metric_key: str = 'overall_accuracy',
                   top_n: int = 10):
    """Prepare leaderboard visualization"""
    try:
        leaderboard = viz_helpers.prepare_leaderboard_data(
            students=students,
            metric_key=metric_key,
            top_n=top_n
        )

        return {
            "success": True,
            "leaderboard": leaderboard,
            "metric": metric_key,
            "total_students": len(students)
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/viz/progress-gauge")
def get_progress_gauge(current_value: float, 
                      max_value: float = 100,
                      target_value: Optional[float] = None):
    """Prepare progress gauge data"""
    try:
        gauge = viz_helpers.prepare_progress_gauge(
            current_value=current_value,
            max_value=max_value,
            target_value=target_value
        )

        return {
            "success": True,
            "gauge": gauge
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# EXPLAINABILITY ENDPOINTS
# ============================================================================

@app.post("/api/explain/features")
def explain_features(feature_data: Dict):
    """Analyze feature importance"""
    try:
        df = pd.DataFrame([feature_data])
        importance = feature_importance.analyze_feature_importance(df)

        return {
            "success": True,
            "feature_importance": importance
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# BATCH OPERATIONS (FIXED)
# ============================================================================

@app.post("/api/batch/grade")
def batch_grade(submissions: List[Dict]):
    """Grade multiple submissions at once"""
    try:
        results = []

        for submission in submissions:
            # Create engine with strategy for each submission
            strategy = submission.get('strategy', 'standard')
            partial_credit_engine = PartialCreditEngine(strategy=strategy)

            result = partial_credit_engine.calculate_partial_credit(
                student_answer=submission['student_answer'],
                correct_answer=submission['correct_answer'],
                max_points=submission['max_points']
            )

            results.append({
                'submission_id': submission.get('id'),
                'result': result,
                'strategy_used': strategy
            })

        return {
            "success": True,
            "results": results,
            "total_graded": len(results)
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/batch/feedback")
def batch_feedback(student_performances: List[Dict]):
    """Generate feedback for multiple students"""
    try:
        feedbacks = []

        for performance in student_performances:
            feedback = feedback_generator.generate_feedback(performance)

            feedbacks.append({
                'student_id': performance.get('student_id'),
                'feedback': feedback
            })

        return {
            "success": True,
            "feedbacks": feedbacks,
            "total_generated": len(feedbacks)
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# UTILITY ENDPOINTS
# ============================================================================

@app.get("/api/strategies")
def get_grading_strategies():
    """Get available grading strategies"""
    return {
        "success": True,
        "strategies": {
            "lenient": {
                "description": "More forgiving grading, higher partial credit",
                "typical_credit": "70-90% for minor errors"
            },
            "standard": {
                "description": "Balanced grading approach",
                "typical_credit": "50-80% for minor errors"
            },
            "strict": {
                "description": "Rigorous grading, lower partial credit",
                "typical_credit": "30-60% for minor errors"
            }
        },
        "default": "standard"
    }


@app.get("/api/mistake-types")
def get_mistake_types():
    """Get recognized mistake types and their typical penalties"""
    return {
        "success": True,
        "mistake_types": {
            "sign_error": {
                "description": "Incorrect sign (positive/negative)",
                "typical_credit_standard": "70%"
            },
            "unit_error": {
                "description": "Incorrect or missing units",
                "typical_credit_standard": "75%"
            },
            "rounding_error": {
                "description": "Minor rounding difference",
                "typical_credit_standard": "90%"
            },
            "calculation_error": {
                "description": "Arithmetic mistake",
                "typical_credit_standard": "50%"
            },
            "method_error": {
                "description": "Wrong approach/method",
                "typical_credit_standard": "30%"
            }
        }
    }


# ============================================================================
# MAIN (FOR TESTING)
# ============================================================================

if __name__ == "__main__":
    import uvicorn

    print("\n" + "="*70)
    print("ðŸš€ ML ANALYTICS API (FULLY CORRECTED)")
    print("="*70)
    print("\nStarting server...")
    print("\nAPI Documentation: http://localhost:8000/docs")
    print("API Root: http://localhost:8000/")
    print("Health Check: http://localhost:8000/health")
    print("\n" + "="*70)
    print("\nFIXES APPLIED:")
    print("  âœ… Grading endpoint - strategy parameter")
    print("  âœ… Personalization endpoint - method signature")
    print("  âœ… All endpoints validated")
    print("\n" + "="*70)
    print("\nAvailable Endpoints:")
    print("  POST /api/personalize - Personalized assignments âœ… FIXED")
    print("  POST /api/grade - Grade student answers âœ… FIXED")
    print("  POST /api/feedback - Generate feedback")
    print("  POST /api/metrics - Calculate metrics")
    print("  POST /api/viz/dashboard - Dashboard data")
    print("  POST /api/explain/features - Feature importance")
    print("\nUtility Endpoints:")
    print("  GET /api/strategies - Available grading strategies")
    print("  GET /api/mistake-types - Recognized mistake types")
    print("\nBatch Operations:")
    print("  POST /api/batch/grade - Batch grading âœ… FIXED")
    print("  POST /api/batch/feedback - Batch feedback")
    print("\n" + "="*70)
    print("\nPress CTRL+C to stop server")
    print("="*70 + "\n")

    uvicorn.run(app, host="0.0.0.0", port=8000)
